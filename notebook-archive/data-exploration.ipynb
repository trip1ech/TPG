{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0badf56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A better way to read the same file, handling BOM and end-of-line truncation\n",
    "\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "\n",
    "# path = \"arrets_ben.csv\"\n",
    "# out_parquet = \"arrets_ben.parquet\"\n",
    "\n",
    "# # --- 1) Read header + dash line, remove BOM automatically ---\n",
    "# with open(path, encoding=\"utf-8-sig\") as f:\n",
    "#     header_line = f.readline().rstrip(\"\\n\")\n",
    "#     dash_line   = f.readline().rstrip(\"\\n\")\n",
    "\n",
    "# # --- 2) Infer column spans from runs of dashes ---\n",
    "# colspecs = [(m.start(), m.end()) for m in re.finditer(r\"-+\", dash_line)]\n",
    "\n",
    "# # Make the last column go to end-of-line to avoid truncation\n",
    "# colspecs[-1] = (colspecs[-1][0], None)\n",
    "\n",
    "# # --- 3) Slice column names from the (BOM-stripped) header ---\n",
    "# raw_names = [header_line[s:] if e is None else header_line[s:e] for s, e in colspecs]\n",
    "# names = []\n",
    "# seen = {}\n",
    "# for nm in map(str.strip, raw_names):\n",
    "#     seen[nm] = seen.get(nm, -1) + 1\n",
    "#     names.append(nm if seen[nm] == 0 else f\"{nm}_{seen[nm]}\")\n",
    "\n",
    "# print(\"Detected columns:\", len(names))\n",
    "# print(names[:10], \"...\")\n",
    "\n",
    "# # --- 4) Read the data as fixed-width (skip header + dashes) ---\n",
    "# df = pd.read_fwf(\n",
    "#     path,\n",
    "#     colspecs=colspecs,\n",
    "#     names=names,\n",
    "#     skiprows=2,\n",
    "#     na_values=[\"NULL\"],\n",
    "#     encoding=\"utf-8-sig\",\n",
    "# )\n",
    "# print(df.shape)\n",
    "# print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd3a24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_o = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "021cb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"DateCourse\"] = pd.to_datetime(df[\"DateCourse\"], errors=\"coerce\")  # , dayfirst=True\n",
    "\n",
    "# start = pd.Timestamp(\"2024-10-01\")\n",
    "# end   = pd.Timestamp(\"2024-11-01\")\n",
    "# df_oct_2024 = df[(df[\"DateCourse\"] >= start) & (df[\"DateCourse\"] < end)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "704e7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_oct_2024.to_csv('oct2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3754522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oct = pd.read_csv('oct2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f04d6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad05d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9add3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# GBM residual experiment (p50 / p85)\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- 0) CONFIG (pick 1–2 months to train, next month to test) ----\n",
    "TRAIN_FROM = \"2024-10-01\"\n",
    "TRAIN_TO   = \"2024-10-15\"\n",
    "TEST_FROM  = \"2024-10-16\"\n",
    "TEST_TO    = \"2024-10-31\"\n",
    "\n",
    "# Optional: focus on a line to prototype (e.g., [18]); set to None for all lines\n",
    "FOCUS_LINES = [18]   # e.g., [18]\n",
    "\n",
    "# ---- 1) BASIC CLEANUP ----\n",
    "# Parse times we need (convert if present)\n",
    "time_cols = [\n",
    "    \"DTDepartTheo\",\"DTArriveeTheo\",\"DTEntreeFenetreArretReal\",\"DTSortieFenetreArretReal\",\n",
    "    \"DTEntreeArretAtp\",\"DTSortieArretAtp\",\n",
    "    \"DTMarquageArretTheo\",\"DTMarquageArretReal\"\n",
    "]\n",
    "for c in time_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# (Optional) line filter for quick prototyping\n",
    "if FOCUS_LINES is not None and \"C_Ligne\" in df.columns:\n",
    "    df[\"C_Ligne\"] = pd.to_numeric(df[\"C_Ligne\"], errors=\"coerce\")\n",
    "    df = df[df[\"C_Ligne\"].isin(FOCUS_LINES)]\n",
    "\n",
    "# Keep essentials as strings/numerics\n",
    "df[\"CodeLong\"] = df[\"CodeLong\"].astype(str).str.strip()\n",
    "if \"C_SensAppl\" in df.columns:\n",
    "    df[\"C_SensAppl\"] = df[\"C_SensAppl\"].astype(str).str.strip()\n",
    "\n",
    "# ---- 2) BUILD SEGMENT ROWS (prev stop -> current stop) ----\n",
    "df = df.sort_values([\"IdCourse\",\"RangArretAsc\"], kind=\"mergesort\")\n",
    "\n",
    "# upstream (prev) columns\n",
    "df[\"prev_CodeLong\"]              = df.groupby(\"IdCourse\")[\"CodeLong\"].shift(1)\n",
    "df[\"prev_DTSortieFenetreReal\"]   = df.groupby(\"IdCourse\")[\"DTSortieFenetreArretReal\"].shift(1)\n",
    "df[\"prev_DTSortieAtp\"]           = df.groupby(\"IdCourse\")[\"DTSortieArretAtp\"].shift(1)\n",
    "df[\"prev_DTMarquageTheo\"]        = df.groupby(\"IdCourse\")[\"DTMarquageArretTheo\"].shift(1)\n",
    "df[\"prev_DTDepartTheo\"]          = df.groupby(\"IdCourse\")[\"DTDepartTheo\"].shift(1)\n",
    "df[\"prev_dwell_window_s\"]        = (\n",
    "    df.groupby(\"IdCourse\")[\"DTSortieFenetreArretReal\"].shift(1) - \n",
    "    df.groupby(\"IdCourse\")[\"DTEntreeFenetreArretReal\"].shift(1)\n",
    ").dt.total_seconds()\n",
    "\n",
    "# demand / punctuality at upstream stop\n",
    "for c in [\"NbMontees\",\"NbDescentes\",\"EcartDepart\"]:\n",
    "    if c in df.columns:\n",
    "        df[f\"prev_{c}\"] = pd.to_numeric(df.groupby(\"IdCourse\")[c].shift(1), errors=\"coerce\")\n",
    "\n",
    "# Distance of the current link\n",
    "if \"DistanceInterArret\" in df.columns:\n",
    "    df[\"DistanceInterArret\"] = pd.to_numeric(df[\"DistanceInterArret\"], errors=\"coerce\")\n",
    "elif \"DistanceTheo\" in df.columns:\n",
    "    df[\"DistanceInterArret\"] = pd.to_numeric(df[\"DistanceTheo\"], errors=\"coerce\")\n",
    "else:\n",
    "    df[\"DistanceInterArret\"] = np.nan\n",
    "\n",
    "# Keep rows where a previous stop exists (i.e., a link is defined)\n",
    "seg = df.dropna(subset=[\"prev_CodeLong\"]).copy()\n",
    "seg[\"from_stop\"] = seg[\"prev_CodeLong\"].astype(str).str.strip()\n",
    "seg[\"to_stop\"]   = seg[\"CodeLong\"].astype(str).str.strip()\n",
    "seg[\"SegmentKey\"] = seg[\"from_stop\"] + \"→\" + seg[\"to_stop\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "280de96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean, non-overlapping definitions ---\n",
    "\n",
    "# --- Scheduled inter-stop runtime (seconds), no fallback ---\n",
    "if \"TempsInterArretTheo\" in seg.columns:\n",
    "    seg[\"sched_link_s\"] = pd.to_numeric(seg[\"TempsInterArretTheo\"], errors=\"coerce\")\n",
    "else:\n",
    "    seg[\"sched_link_s\"] = np.nan\n",
    "\n",
    "# keep rows with a valid scheduled time\n",
    "seg = seg[np.isfinite(seg[\"sched_link_s\"])].copy()\n",
    "\n",
    "# 1) Dwell at current stop (window time)\n",
    "seg[\"dwell_curr_s\"] = (seg[\"DTSortieFenetreArretReal\"] - seg[\"DTEntreeFenetreArretReal\"]).dt.total_seconds()\n",
    "\n",
    "# 2) Pure link drive time (window-to-window, excludes both dwells)\n",
    "seg[\"drive_time_s\"] = (seg[\"DTEntreeFenetreArretReal\"] - seg[\"prev_DTSortieFenetreReal\"]).dt.total_seconds()\n",
    "\n",
    "# Keep valid rows\n",
    "seg = seg[(seg[\"drive_time_s\"] > 0) & (seg[\"sched_link_s\"] > 0)].copy()\n",
    "\n",
    "# 3) Target: residual of drive time vs scheduled inter-stop time\n",
    "seg[\"y_resid_s\"] = seg[\"drive_time_s\"] - seg[\"sched_link_s\"]\n",
    "\n",
    "# 4) Distance and physics-like speed (minus 70 m for the two windows)\n",
    "seg[\"distance_m\"] = pd.to_numeric(seg[\"DistanceInterArret\"], errors=\"coerce\") - 70.0\n",
    "seg.loc[seg[\"distance_m\"] <= 0, \"distance_m\"] = np.nan\n",
    "seg[\"phys_speed_kmh\"] = 3.6 * seg[\"distance_m\"] / seg[\"drive_time_s\"]\n",
    "\n",
    "# 5) Upstream dwell as a feature (no overlap with drive_time_s)\n",
    "seg[\"dwell_prev_s\"] = seg[\"prev_dwell_window_s\"]\n",
    "\n",
    "# 6) Time anchors unchanged\n",
    "seg[\"link_start_time\"] = seg[\"prev_DTDepartTheo\"]\n",
    "seg = seg[pd.notna(seg[\"link_start_time\"])].copy()\n",
    "seg[\"hour\"] = seg[\"link_start_time\"].dt.hour\n",
    "seg[\"dow\"]  = seg[\"link_start_time\"].dt.dayofweek\n",
    "seg[\"is_weekend\"] = seg[\"dow\"].isin([5,6]).astype(int)\n",
    "seg[\"hour_sin\"] = np.sin(2*np.pi*seg[\"hour\"]/24.0)\n",
    "seg[\"hour_cos\"] = np.cos(2*np.pi*seg[\"hour\"]/24.0)\n",
    "\n",
    "# final feature list (non-overlapping with the target)\n",
    "feat_cols = [\n",
    "    \"distance_m\",\"dwell_prev_s\",\"ecart_prev_s\",\n",
    "    \"board_prev\",\"alight_prev\",\n",
    "    \"hour_sin\",\"hour_cos\",\"dow\",\"is_weekend\",\n",
    "    \"from_stop\",\"to_stop\",\"line\",\"dir\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b5576f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 180499\n",
      "     from_stop to_stop  distance_m  drive_time_s  dwell_curr_s  y_resid_s\n",
      "769     CVIN04  LYON01       261.0          67.0          36.0      -13.0\n",
      "1013    LYON01  POTE01       345.0          47.0          50.0      -55.0\n",
      "1251    POTE01  SERV01       248.0          22.0          30.0      -56.0\n",
      "1492    SERV01  VIUS01       354.0          37.0          41.0      -30.0\n",
      "1727    VIUS01  BOHT01       507.0          69.0          41.0      -24.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Rows:\", len(seg))\n",
    "print(seg[[\"from_stop\",\"to_stop\",\"distance_m\",\"drive_time_s\",\"dwell_curr_s\",\"y_resid_s\"]].head())\n",
    "\n",
    "# Period label just for plotting (we still keep hour-based features in models)\n",
    "def period(dt):\n",
    "    h = dt.hour; d = dt.dayofweek\n",
    "    if d==5: return \"Sat\"\n",
    "    if d==6: return \"Sun\"\n",
    "    if 7<=h<9: return \"AM\"\n",
    "    if 9<=h<16: return \"Day\"\n",
    "    if 16<=h<19: return \"PM\"\n",
    "    if 19<=h<23: return \"Eve\"\n",
    "    return \"Other\"\n",
    "seg[\"period_plot\"] = seg[\"link_start_time\"].map(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71e0897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "x = seg[\"y_resid_s\"].dropna()\n",
    "x = x[(x>=-200) & (x<=200)]\n",
    "plt.hist(x, bins=60)\n",
    "plt.title(\"Distribution of link run times residuals\")\n",
    "plt.xlabel(\"Seconds\"); plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0518600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77fde8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6360c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39436d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321cd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c8fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 6) TIME-AWARE SPLIT ----\n",
    "mask_tr = (seg[\"link_start_time\"]>=pd.to_datetime(TRAIN_FROM)) & (seg[\"link_start_time\"]<=pd.to_datetime(TRAIN_TO))\n",
    "mask_te = (seg[\"link_start_time\"]>=pd.to_datetime(TEST_FROM))  & (seg[\"link_start_time\"]<=pd.to_datetime(TEST_TO))\n",
    "\n",
    "train = seg[mask_tr].copy()\n",
    "test  = seg[mask_te].copy()\n",
    "\n",
    "# Historical p50/p85 residual (segment × period) from TRAIN (baselines)\n",
    "hist_p50 = train.groupby([\"SegmentKey\",\"period\"])[\"y_resid_s\"].median()\n",
    "hist_p85 = train.groupby([\"SegmentKey\",\"period\"])[\"y_resid_s\"].quantile(0.85)\n",
    "\n",
    "def baseline_from_hist(dfX, qmap):\n",
    "    keys = list(zip(dfX[\"SegmentKey\"], dfX[\"period\"]))\n",
    "    vals = [qmap.get(k, 0.0) for k in keys]  # fallback to 0 residual if unseen\n",
    "    return np.array(vals, dtype=float)\n",
    "\n",
    "def baseline_from_hist_fast(dfX: pd.DataFrame, qseries: pd.Series, default=0.0) -> np.ndarray:\n",
    "    out = (dfX[[\"SegmentKey\",\"period\"]]\n",
    "           .merge(qseries.rename(\"q\"),\n",
    "                  left_on=[\"SegmentKey\",\"period\"],\n",
    "                  right_index=True,\n",
    "                  how=\"left\")[\"q\"]\n",
    "           .fillna(default)\n",
    "           .to_numpy(dtype=float))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d34bfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, numpy as np, pandas as pd\n",
    "\n",
    "def lap(msg, _t=[None]):\n",
    "    now = time.time()\n",
    "    if _t[0] is None:\n",
    "        print(f\"[{msg}]\"); _t[0] = now\n",
    "    else:\n",
    "        print(f\"[{msg}] {now - _t[0]:.2f}s\"); _t[0] = now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67b1d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM: 4.6.0\n",
      "[split train/val]\n",
      "fit/val/test: 73940 10043 83337\n",
      "[downsample train by period] 0.07s\n",
      "downsampled fit: 36970\n",
      "[cap_rare categories] 0.12s\n",
      "[build X/y] 0.06s\n",
      "X_fit / X_val / X_te: (36970, 14) (10043, 14) (83337, 14)\n",
      "[unify categorical vocab] 0.02s\n",
      "[sanitize numerics] 0.06s\n",
      "X_fit top-NaN rates:\n",
      "phys_speed_kmh    0.001271\n",
      "distance_m        0.001244\n",
      "dwell_prev_s      0.000000\n",
      "ecart_prev_s      0.000000\n",
      "dtype: float64\n",
      "\n",
      "X_val top-NaN rates:\n",
      "distance_m        0.001494\n",
      "phys_speed_kmh    0.001494\n",
      "dwell_prev_s      0.000000\n",
      "ecart_prev_s      0.000000\n",
      "dtype: float64\n",
      "\n",
      "X_te top-NaN rates:\n",
      "phys_speed_kmh    0.001812\n",
      "distance_m        0.001452\n",
      "dwell_prev_s      0.000000\n",
      "ecart_prev_s      0.000000\n",
      "dtype: float64\n",
      "\n",
      "after drop NaN/Inf -> X_fit: (36923, 14) X_val: (10028, 14)\n"
     ]
    }
   ],
   "source": [
    "# ========= ROBUST TRAIN BLOCK (diagnose + fix, with EN comments) =========\n",
    "import os, gc, time, warnings\n",
    "import numpy as np, pandas as pd, lightgbm as lgb\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 0) Utilities: simple timer\n",
    "# ---------------------------\n",
    "def lap(msg, _t=[None]):\n",
    "    \"\"\"Print a message and elapsed time since last lap().\"\"\"\n",
    "    now = time.time()\n",
    "    if _t[0] is None:\n",
    "        print(f\"[{msg}]\"); _t[0] = now\n",
    "    else:\n",
    "        print(f\"[{msg}] {now - _t[0]:.2f}s\"); _t[0] = now\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Thread caps for macOS stability (avoid oversubscription)\n",
    "# ---------------------------\n",
    "\n",
    "print(\"LightGBM:\", lgb.__version__)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Time-aware split: small tail of TRAIN as validation\n",
    "# ---------------------------\n",
    "VAL_DAYS = 3\n",
    "val_cut = pd.to_datetime(TRAIN_TO) - pd.Timedelta(days=VAL_DAYS - 1)\n",
    "\n",
    "lap(\"split train/val\")\n",
    "train_fit = train[train[\"link_start_time\"] < val_cut].copy()\n",
    "val_fit   = train[train[\"link_start_time\"] >= val_cut].copy()\n",
    "print(\"fit/val/test:\", len(train_fit), len(val_fit), len(test))\n",
    "\n",
    "# If validation is empty (e.g., short window), fallback to VAL_DAYS=1\n",
    "if len(val_fit) == 0:\n",
    "    print(\"⚠️ val is empty; retry with VAL_DAYS=1\")\n",
    "    VAL_DAYS = 1\n",
    "    val_cut = pd.to_datetime(TRAIN_TO)\n",
    "    train_fit = train[train[\"link_start_time\"] < val_cut].copy()\n",
    "    val_fit   = train[train[\"link_start_time\"] >= val_cut].copy()\n",
    "    print(\"fit/val/test:\", len(train_fit), len(val_fit), len(test))\n",
    "\n",
    "# ---------------------------\n",
    "# 3) (Optional) speed-up: downsample training by period (keeps distribution)\n",
    "# ---------------------------\n",
    "FAST = True\n",
    "DEBUG_FRAC = 0.5  # keep 50% for faster iteration; tune as needed\n",
    "if FAST and len(train_fit) > 40000:\n",
    "    lap(\"downsample train by period\")\n",
    "    train_fit = (train_fit\n",
    "                 .groupby(\"period\", group_keys=False)\n",
    "                 .apply(lambda x: x.sample(frac=DEBUG_FRAC, random_state=42))\n",
    "                 .reset_index(drop=True))\n",
    "    print(\"downsampled fit:\", len(train_fit))\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Cap rare categories to reduce cardinality\n",
    "# ---------------------------\n",
    "lap(\"cap_rare categories\")\n",
    "def cap_rare(s: pd.Series, min_count=50):\n",
    "    vc = s.value_counts()\n",
    "    keep = set(vc[vc >= min_count].index)\n",
    "    return s.where(s.isin(keep), \"OTHER\")\n",
    "\n",
    "cat_cols = [\"from_stop\",\"to_stop\",\"line\",\"dir\"]\n",
    "for c in cat_cols:\n",
    "    train_fit[c] = cap_rare(train_fit[c].astype(str), 50)\n",
    "    val_fit[c]   = cap_rare(val_fit[c].astype(str), 50)\n",
    "    test[c]      = cap_rare(test[c].astype(str), 50)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Build X / y\n",
    "# ---------------------------\n",
    "lap(\"build X/y\")\n",
    "# feat_cols must include your numeric + categorical features in the right order\n",
    "# e.g.:\n",
    "# feat_cols = [\n",
    "#   \"distance_m\",\"phys_speed_kmh\",\"dwell_prev_s\",\"ecart_prev_s\",\n",
    "#   \"board_prev\",\"alight_prev\",\"hour_sin\",\"hour_cos\",\"dow\",\"is_weekend\",\n",
    "#   \"from_stop\",\"to_stop\",\"line\",\"dir\"\n",
    "# ]\n",
    "\n",
    "X_fit = train_fit[feat_cols].copy()\n",
    "y_fit = train_fit[\"y_resid_s\"].astype(float).values\n",
    "X_val = val_fit[feat_cols].copy()\n",
    "y_val = val_fit[\"y_resid_s\"].astype(float).values\n",
    "X_te  = test[feat_cols].copy()\n",
    "y_te  = test[\"y_resid_s\"].astype(float).values\n",
    "print(\"X_fit / X_val / X_te:\", X_fit.shape, X_val.shape, X_te.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Make categorical vocabularies CONSISTENT across all splits\n",
    "# ---------------------------\n",
    "lap(\"unify categorical vocab\")\n",
    "for c in cat_cols:\n",
    "    cats = sorted( set(X_fit[c].astype(str))\n",
    "                 | set(X_val[c].astype(str))\n",
    "                 | set(X_te[c].astype(str))\n",
    "                 | {\"OTHER\"} )\n",
    "    ctype = CategoricalDtype(categories=cats, ordered=False)\n",
    "    X_fit[c] = X_fit[c].astype(ctype)\n",
    "    X_val[c] = X_val[c].astype(ctype)\n",
    "    X_te[c]  = X_te[c].astype(ctype)\n",
    "\n",
    "cat_idx = [X_fit.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Sanitize numerics: no NaN/Inf; drop rows with missing numerics in fit/val\n",
    "# ---------------------------\n",
    "lap(\"sanitize numerics\")\n",
    "num_cols = [c for c in feat_cols if c not in cat_cols]\n",
    "\n",
    "for Xname, X in [(\"X_fit\", X_fit), (\"X_val\", X_val), (\"X_te\", X_te)]:\n",
    "    X[num_cols] = X[num_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    # quick report of top NaN rates\n",
    "    print(f\"{Xname} top-NaN rates:\\n{X[num_cols].isna().mean().sort_values(ascending=False).head(4)}\\n\")\n",
    "\n",
    "fit_mask = np.isfinite(y_fit)\n",
    "val_mask = np.isfinite(y_val)\n",
    "fit_mask &= np.all(np.isfinite(X_fit[num_cols].to_numpy()), axis=1)\n",
    "val_mask &= np.all(np.isfinite(X_val[num_cols].to_numpy()), axis=1)\n",
    "\n",
    "X_fit = X_fit.iloc[fit_mask].copy(); y_fit = y_fit[fit_mask]\n",
    "X_val = X_val.iloc[val_mask].copy(); y_val = y_val[val_mask]\n",
    "print(\"after drop NaN/Inf ->\",\n",
    "      \"X_fit:\", X_fit.shape, \"X_val:\", X_val.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# 8) LightGBM params: stable & fast on CPU (row-wise, limited threads)\n",
    "# ---------------------------\n",
    "base_params = dict(\n",
    "    learning_rate=0.10,\n",
    "    n_estimators=600,          # increase later when everything is stable\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    min_data_in_leaf=500,\n",
    "    max_bin=63,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    n_jobs=4,                  # important on macOS\n",
    "    force_row_wise=True,\n",
    "    max_cat_to_onehot=4,\n",
    "    max_cat_threshold=16,\n",
    "    min_data_per_group=100,\n",
    "    cat_smooth=10,\n",
    "    verbosity=0                # keep callbacks visible, silence tree-level spam\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df96c891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> train p50 (native categorical)\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[20]\tvalid_0's l1: 11.7538\n",
      "[40]\tvalid_0's l1: 10.6329\n",
      "[60]\tvalid_0's l1: 10.3522\n",
      "[80]\tvalid_0's l1: 10.2256\n",
      "[100]\tvalid_0's l1: 10.1449\n",
      "[120]\tvalid_0's l1: 10.0761\n",
      "[140]\tvalid_0's l1: 10.0297\n",
      "[160]\tvalid_0's l1: 9.99675\n",
      "[180]\tvalid_0's l1: 9.96568\n",
      "[200]\tvalid_0's l1: 9.91696\n",
      "[220]\tvalid_0's l1: 9.89276\n",
      "[240]\tvalid_0's l1: 9.87882\n",
      "[260]\tvalid_0's l1: 9.86165\n",
      "[280]\tvalid_0's l1: 9.83857\n",
      "[300]\tvalid_0's l1: 9.82688\n",
      "[320]\tvalid_0's l1: 9.80931\n",
      "[340]\tvalid_0's l1: 9.79634\n",
      "[360]\tvalid_0's l1: 9.78627\n",
      "[380]\tvalid_0's l1: 9.77541\n",
      "[400]\tvalid_0's l1: 9.76776\n",
      "[420]\tvalid_0's l1: 9.75612\n",
      "[440]\tvalid_0's l1: 9.74836\n",
      "[460]\tvalid_0's l1: 9.73909\n",
      "[480]\tvalid_0's l1: 9.72916\n",
      "[500]\tvalid_0's l1: 9.72488\n",
      "[520]\tvalid_0's l1: 9.71722\n",
      "[540]\tvalid_0's l1: 9.71517\n",
      "[560]\tvalid_0's l1: 9.70816\n",
      "[580]\tvalid_0's l1: 9.70145\n",
      "[600]\tvalid_0's l1: 9.6663\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid_0's l1: 9.6663\n",
      "<<< p50 done in 1.15s, best_iter=600\n",
      ">>> train p85 (native categorical)\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[20]\tvalid_0's quantile: 4.29496\n",
      "[40]\tvalid_0's quantile: 3.89779\n",
      "[60]\tvalid_0's quantile: 3.83103\n",
      "[80]\tvalid_0's quantile: 3.79132\n",
      "[100]\tvalid_0's quantile: 3.77125\n",
      "[120]\tvalid_0's quantile: 3.75208\n",
      "[140]\tvalid_0's quantile: 3.7405\n",
      "[160]\tvalid_0's quantile: 3.73404\n",
      "[180]\tvalid_0's quantile: 3.73356\n",
      "[200]\tvalid_0's quantile: 3.70566\n",
      "[220]\tvalid_0's quantile: 3.69929\n",
      "[240]\tvalid_0's quantile: 3.69838\n",
      "[260]\tvalid_0's quantile: 3.70019\n",
      "[280]\tvalid_0's quantile: 3.69839\n",
      "[300]\tvalid_0's quantile: 3.69866\n",
      "[320]\tvalid_0's quantile: 3.69632\n",
      "[340]\tvalid_0's quantile: 3.6961\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid_0's quantile: 3.69437\n",
      "<<< p85 done in 0.65s, best_iter=329\n",
      ">>> predict\n",
      "<<< predict done\n",
      "[hist baselines] 246.69s\n",
      "[hist baselines done] 0.06s\n",
      "[metrics] 0.00s\n",
      "[metrics done] 0.00s\n",
      "MAE residual (sec) — model p50: 14.7 | hist p50: 18.3 | zero: 22.6\n",
      "Coverage @p85 — model: 0.801 | hist: 0.840\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 8) LightGBM params: stable & fast on CPU (row-wise, limited threads)\n",
    "# ---------------------------\n",
    "import os, time, gc\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "# （建議放在最前面的 cell，但這裡再保險一次）\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"2\")          # 先保守，確定不卡再調 4\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"VECLIB_MAXIMUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"BLIS_NUM_THREADS\", \"1\")\n",
    "\n",
    "base_params = dict(\n",
    "    learning_rate=0.10,\n",
    "    n_estimators=600,          # 先 600，確認穩定後可加\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    min_data_in_leaf=500,\n",
    "    max_bin=63,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    n_jobs=2,                  # macOS 請避免 -1，穩定後可改 4\n",
    "    force_row_wise=True,\n",
    "    max_cat_to_onehot=4,\n",
    "    max_cat_threshold=16,\n",
    "    min_data_per_group=100,\n",
    "    cat_smooth=10\n",
    ")\n",
    "\n",
    "# ---------- preflight：檢查資料 ----------\n",
    "cat_cols = [\"from_stop\",\"to_stop\",\"line\",\"dir\"]\n",
    "num_cols = [c for c in feat_cols if c not in cat_cols]\n",
    "\n",
    "def _assert_ok_split(name, X, y):\n",
    "    assert isinstance(X, pd.DataFrame), f\"{name} must be DataFrame\"\n",
    "    assert isinstance(y, np.ndarray), f\"{name} y must be numpy array\"\n",
    "    assert X.shape[0] == len(y), f\"{name} X/y length mismatch\"\n",
    "    assert all(c in X.columns for c in feat_cols), f\"{name} missing features\"\n",
    "    assert np.isfinite(y).all(), f\"{name} y has NaN/Inf\"\n",
    "    bad = X[num_cols].to_numpy()\n",
    "    assert np.isfinite(bad).all(), f\"{name} numeric features have NaN/Inf\"\n",
    "\n",
    "# cast numerics → float32（加速 & 降記憶體）\n",
    "X_fit[num_cols] = X_fit[num_cols].astype(\"float32\")\n",
    "X_val[num_cols] = X_val[num_cols].astype(\"float32\")\n",
    "X_te [num_cols] = X_te [num_cols].astype(\"float32\")\n",
    "\n",
    "# 重新計算 cat_idx（避免前面有改過欄位順序）\n",
    "cat_idx = [X_fit.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "# 檢查 split\n",
    "_assert_ok_split(\"FIT\", X_fit, y_fit)\n",
    "_assert_ok_split(\"VAL\", X_val, y_val)\n",
    "\n",
    "# ---------- v1：用原生 categorical（期望印出 log） ----------\n",
    "print(\">>> train p50 (native categorical)\", flush=True)\n",
    "t0 = time.time()\n",
    "m50 = lgb.LGBMRegressor(objective=\"regression_l1\", **base_params)\n",
    "m50.fit(\n",
    "    X_fit, y_fit,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"l1\",\n",
    "    categorical_feature=cat_idx,\n",
    "    callbacks=[lgb.log_evaluation(period=20),\n",
    "               lgb.early_stopping(stopping_rounds=30)]\n",
    ")\n",
    "print(f\"<<< p50 done in {time.time()-t0:.2f}s, best_iter={getattr(m50,'best_iteration_',None)}\", flush=True)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\">>> train p85 (native categorical)\", flush=True)\n",
    "t1 = time.time()\n",
    "m85 = lgb.LGBMRegressor(objective=\"quantile\", alpha=0.85, **base_params)\n",
    "m85.fit(\n",
    "    X_fit, y_fit,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"quantile\",\n",
    "    categorical_feature=cat_idx,\n",
    "    callbacks=[lgb.log_evaluation(period=20),\n",
    "               lgb.early_stopping(stopping_rounds=30)]\n",
    ")\n",
    "print(f\"<<< p85 done in {time.time()-t1:.2f}s, best_iter={getattr(m85,'best_iteration_',None)}\", flush=True)\n",
    "\n",
    "# 如果到這裡兩個模型都順利印出 [20]/[40] 日誌，就不需要 fallback。\n",
    "# ---------- 如果上面 30 秒內沒有任何日誌，改走 ordinal fallback ----------\n",
    "if (time.time() - t0) > 30 and getattr(m50, \"best_iteration_\", None) is None:\n",
    "    print(\"⚠️  No logs within 30s; fallback to ordinal-encoded categoricals.\", flush=True)\n",
    "\n",
    "    def ordinalize(train_s: pd.Series, valid_s: pd.Series, test_s: pd.Series):\n",
    "        cats = pd.Index(sorted(pd.Series(train_s.astype(str).unique()).tolist()))\n",
    "        mapping = {k:i for i,k in enumerate(cats)}\n",
    "        def _map(s): return s.astype(str).map(mapping).fillna(-1).astype(\"int32\")\n",
    "        return _map(train_s), _map(valid_s), _map(test_s)\n",
    "\n",
    "    Xo_fit, Xo_val, Xo_te = X_fit.copy(), X_val.copy(), X_te.copy()\n",
    "    for c in cat_cols:\n",
    "        Xo_fit[c], Xo_val[c], Xo_te[c] = ordinalize(X_fit[c], X_val[c], X_te[c])\n",
    "\n",
    "    # 不傳 categorical_feature，讓 LGBM 當一般數值處理\n",
    "    print(\">>> train p50 (ordinal cats)\", flush=True)\n",
    "    t0b = time.time()\n",
    "    m50 = lgb.LGBMRegressor(objective=\"regression_l1\", **base_params)\n",
    "    m50.fit(\n",
    "        Xo_fit[feat_cols], y_fit,\n",
    "        eval_set=[(Xo_val[feat_cols], y_val)],\n",
    "        eval_metric=\"l1\",\n",
    "        callbacks=[lgb.log_evaluation(period=20),\n",
    "                   lgb.early_stopping(stopping_rounds=30)]\n",
    "    )\n",
    "    print(f\"<<< p50 done (ordinal) in {time.time()-t0b:.2f}s, best_iter={getattr(m50,'best_iteration_',None)}\", flush=True)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    print(\">>> train p85 (ordinal cats)\", flush=True)\n",
    "    t1b = time.time()\n",
    "    m85 = lgb.LGBMRegressor(objective=\"quantile\", alpha=0.85, **base_params)\n",
    "    m85.fit(\n",
    "        Xo_fit[feat_cols], y_fit,\n",
    "        eval_set=[(Xo_val[feat_cols], y_val)],\n",
    "        eval_metric=\"quantile\",\n",
    "        callbacks=[lgb.log_evaluation(period=20),\n",
    "                   lgb.early_stopping(stopping_rounds=30)]\n",
    "    )\n",
    "    print(f\"<<< p85 done (ordinal) in {time.time()-t1b:.2f}s, best_iter={getattr(m85,'best_iteration_',None)}\", flush=True)\n",
    "\n",
    "    # 用 ordinal 的特徵做預測\n",
    "    print(\">>> predict (ordinal)\", flush=True)\n",
    "    pred50 = m50.predict(Xo_te[feat_cols], num_iteration=getattr(m50,\"best_iteration_\",None))\n",
    "    pred85 = m85.predict(Xo_te[feat_cols], num_iteration=getattr(m85,\"best_iteration_\",None))\n",
    "    print(\"<<< predict done (ordinal)\", flush=True)\n",
    "else:\n",
    "    # ---------- v1 正常路徑：用原生 categorical 做預測 ----------\n",
    "    print(\">>> predict\", flush=True)\n",
    "    pred50 = m50.predict(X_te, num_iteration=getattr(m50,\"best_iteration_\",None))\n",
    "    pred85 = m85.predict(X_te, num_iteration=getattr(m85,\"best_iteration_\",None))\n",
    "    print(\"<<< predict done\", flush=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 12) Vectorized historical baselines (no Python loops)\n",
    "# ---------------------------\n",
    "lap(\"hist baselines\")\n",
    "test[\"period\"]  = test[\"period\"].fillna(\"Other\").astype(str)\n",
    "train[\"period\"] = train[\"period\"].fillna(\"Other\").astype(str)\n",
    "\n",
    "b_hist50 = (test[[\"SegmentKey\",\"period\"]]\n",
    "            .merge(hist_p50.rename(\"q\"),\n",
    "                   left_on=[\"SegmentKey\",\"period\"],\n",
    "                   right_index=True, how=\"left\")[\"q\"]\n",
    "            .fillna(0.0).to_numpy(dtype=float))\n",
    "b_hist85 = (test[[\"SegmentKey\",\"period\"]]\n",
    "            .merge(hist_p85.rename(\"q\"),\n",
    "                   left_on=[\"SegmentKey\",\"period\"],\n",
    "                   right_index=True, how=\"left\")[\"q\"]\n",
    "            .fillna(0.0).to_numpy(dtype=float))\n",
    "lap(\"hist baselines done\")\n",
    "\n",
    "# ---------------------------\n",
    "# 13) Metrics\n",
    "# ---------------------------\n",
    "lap(\"metrics\")\n",
    "def mae(a, b): return float(np.mean(np.abs(a - b)))\n",
    "mae_model = mae(y_te, pred50)\n",
    "mae_hist  = mae(y_te, b_hist50)\n",
    "mae_zero  = mae(y_te, np.zeros_like(y_te))\n",
    "cov_model = float(np.mean(y_te <= pred85))   # ~0.85 target\n",
    "cov_hist  = float(np.mean(y_te <= b_hist85))\n",
    "lap(\"metrics done\")\n",
    "\n",
    "print(f\"MAE residual (sec) — model p50: {mae_model:.1f} | hist p50: {mae_hist:.1f} | zero: {mae_zero:.1f}\")\n",
    "print(f\"Coverage @p85 — model: {cov_model:.3f} | hist: {cov_hist:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da876a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98ee92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf2b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c68a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4586f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- 8) METRICS & BASELINES ----\n",
    "def mae(a, b): return float(np.mean(np.abs(a-b)))\n",
    "\n",
    "# Baselines\n",
    "b_hist50 = baseline_from_hist(test, hist_p50)  # historical median residual\n",
    "b_hist85 = baseline_from_hist(test, hist_p85)  # historical p85 residual\n",
    "\n",
    "# Schedule \"baseline\" is residual=0 ⇒ MAE = mean(|y|)\n",
    "b_zero = np.zeros_like(y_te)\n",
    "\n",
    "# Evaluate\n",
    "mae_model = mae(y_te, pred50)\n",
    "mae_hist  = mae(y_te, b_hist50)\n",
    "mae_zero  = mae(y_te, b_zero)\n",
    "\n",
    "cov_model = float(np.mean(y_te <= pred85))     # should be ~0.85 if well calibrated\n",
    "cov_hist  = float(np.mean(y_te <= b_hist85))\n",
    "\n",
    "print(f\"[SPLIT] Train {TRAIN_FROM}..{TRAIN_TO} → Test {TEST_FROM}..{TEST_TO}\")\n",
    "print(f\"Samples: train={len(train):,}, test={len(test):,}\")\n",
    "print(f\"MAE residual (sec):  model p50 = {mae_model:.1f} | hist p50 = {mae_hist:.1f} | zero = {mae_zero:.1f}\")\n",
    "print(f\"Coverage @p85:       model = {cov_model:.3f} | hist = {cov_hist:.3f}\")\n",
    "\n",
    "# ---- 9) SIMPLE BREAKDOWNS (by period / by line) ----\n",
    "def breakdown_mae(df_te, y_true, y_pred, key):\n",
    "    tmp = df_te[[key]].copy()\n",
    "    tmp[\"ae\"] = np.abs(y_true - y_pred)\n",
    "    out = tmp.groupby(key)[\"ae\"].mean().sort_values()\n",
    "    return out\n",
    "\n",
    "print(\"\\n[MAE by period] (model p50)\")\n",
    "print(breakdown_mae(test, y_te, pred50, \"period\"))\n",
    "\n",
    "if \"line\" in test.columns:\n",
    "    print(\"\\n[MAE by line] (model p50)\")\n",
    "    print(breakdown_mae(test, y_te, pred50, \"line\"))\n",
    "\n",
    "# ---- 10) FEATURE IMPORTANCE (gain-based) ----\n",
    "imp = pd.Series(m50.booster_.feature_importance(importance_type=\"gain\"), index=m50.booster_.feature_name())\n",
    "imp = imp.sort_values(ascending=False)\n",
    "print(\"\\n[Top features by gain]\\n\", imp.head(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e7721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97419a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb80b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9dd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb575313",
   "metadata": {},
   "outputs": [],
   "source": [
    "m50 = lgb.LGBMRegressor(\n",
    "    objective=\"regression_l1\",\n",
    "    learning_rate=0.10,\n",
    "    n_estimators=10,              # 只跑 10 棵，必定很快\n",
    "    num_leaves=31, max_depth=6, min_data_in_leaf=500,\n",
    "    max_bin=63, feature_fraction=0.8, bagging_fraction=0.8, bagging_freq=1,\n",
    "    n_jobs=4,                     # macOS 不要用 -1\n",
    "    verbosity=0\n",
    ")\n",
    "print(\"[sklearn p50] before fit\")\n",
    "m50.fit(\n",
    "    X_fit, y_fit,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"l1\",\n",
    "    categorical_feature=[X_fit.columns.get_loc(c) for c in cat_cols],\n",
    "    callbacks=[lgb.log_evaluation(1), lgb.early_stopping(5)]\n",
    ")\n",
    "print(\"[sklearn p50] after fit, best_iter:\", getattr(m50, \"best_iteration_\", None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
